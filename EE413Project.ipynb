{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjb0VuaXS7RX"
   },
   "source": [
    "All parameters should be defined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IVWRllLOS7nF"
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"input_path\" : \"wallpaper.jpg\",\n",
    "    \"output_path\" : \"output_image.jpg\",\n",
    "    \"wave_dec_1\" : {\"wave_type\" : 'haar', \"level\" : 3},\n",
    "    \"wave_dec_2\" : {\"wave_type\" : 'db2', \"level\" : 5},\n",
    "    \"thresholds_percentage\" : [0.05, 0.1, 0.15, 0.2]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJPcQ_uvAzV4"
   },
   "source": [
    "Pick an image of your choice. Load the image using appropriate commands. If it is a colored image, convert it to grayscale. Save the image in a two-dimensional matrix X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "cbq5L_mkAyJq"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the input and output paths\n",
    "input_path = parameters[\"input_path\"]\n",
    "output_path = parameters[\"output_path\"]\n",
    "\n",
    "# Load the input image\n",
    "img = Image.open(input_path)\n",
    "\n",
    "\n",
    "# Check if the image is grayscale\n",
    "if img.mode != \"L\":\n",
    "    # Convert the image to grayscale\n",
    "    img = img.convert(\"L\")\n",
    "\n",
    "X = np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAiMLMSvBIyb"
   },
   "source": [
    "Determine the total number of bytes needed to store this image in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vnx7j2xAyvQ",
    "outputId": "e3c4847a-c031-419c-cecb-805e38841c35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of bytes needed to store this image in X using Method 1 = 14075528\n",
      "total number of bytes needed to store this image in X using Method 2 = 14075528\n"
     ]
    }
   ],
   "source": [
    "# Method 1\n",
    "unique_items = np.unique(X) # Removing repeated items\n",
    "bits_for_item = int(np.ceil(np.log2(len(unique_items)))) \n",
    "total_bytes = (X.size * bits_for_item) // 8\n",
    "print(\"total number of bytes needed to store this image in X using Method 1 =\", total_bytes)\n",
    "\n",
    "# Method 2\n",
    "total_bytes = X.nbytes # This function do the same as Method 1. so we will use it instead of Method 1\n",
    "print(\"total number of bytes needed to store this image in X using Method 2 =\", total_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sx-xNXm_BYbL"
   },
   "source": [
    "Convert X to a vector-form. Call it x. Verify that the size (bytes) of the new variable x\n",
    "matches that of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "mPdaUyXUBbsG"
   },
   "outputs": [],
   "source": [
    "x = X.flatten() # Convert to 1d array\n",
    "\n",
    "# this will raise an error statment if (x.nbytes != X.nbytes)\n",
    "assert x.nbytes == X.nbytes, \"the size (bytes) of the new variable x doesn't matches that of X\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShWJ0opuBbJK"
   },
   "source": [
    "Perform multi-level decomposition of this signal using two different wavelets of your own\n",
    "choice:\n",
    "• Perform 3-level decomposition\n",
    "• Perform 5-level decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NXeKjupMBftL"
   },
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "# Doing wavelet decomposition\n",
    "wav_coff_1 = pywt.wavedec(x, parameters[\"wave_dec_1\"][\"wave_type\"], level=parameters[\"wave_dec_1\"][\"level\"])\n",
    "wav_coff_2 = pywt.wavedec(x, parameters[\"wave_dec_2\"][\"wave_type\"], level=parameters[\"wave_dec_2\"][\"level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66QmttV_0ud6",
    "outputId": "418d0bf3-cb40-4a84-f21b-53135c35a569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes after decomposition and before thresholding:\n",
      "\n",
      "Signal 1 ==> 112604224 bytes\n",
      "Signal 2 ==> 112604328 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Sizes after decomposition and before thresholding:\\n\")\n",
    "size = sum([arr.nbytes for arr in wav_coff_1])\n",
    "print(\"Signal 1 ==>\", size, \"bytes\")\n",
    "size = sum([arr.nbytes for arr in wav_coff_2])\n",
    "print(\"Signal 2 ==>\", size, \"bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTZsF7VlBfz9"
   },
   "source": [
    "Perform hard thresholding on the decompositions from the previous step (i.e., the wavelet\n",
    "coefficients resulting from the previous step). Perform the thresholding separately on both\n",
    "3-level and 5-level decompositions. In this step, use a range of thresholds selected between\n",
    "5%−20% of the maximum wavelet coefficient value. Specifically, use the following thresholds:\n",
    "5%, 10%, 15%, 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MKUu9PQaBiQl"
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "###### THIS CODE WAS CREATED FOR ONLY 1 SIGNAL (JUST FOR EXPLANATION) ==> DON'T RUN IT  ######\n",
    "##############################################################################################\n",
    "\n",
    "thresholds_percentage = parameters['thresholds_percentage']\n",
    "thresholds = []\n",
    "wav_coff_thresh = []\n",
    "\n",
    "# Find the threshold for each array in the list\n",
    "for i, arr in enumerate(wav_coff_1):\n",
    "    max_value = np.max(arr)\n",
    "    thresholds.append([])  # Create an empty list for each array\n",
    "    for j in range(len(thresholds_percentage)):\n",
    "      threshold = max_value * thresholds_percentage[j] \n",
    "      thresholds[i].append(threshold)\n",
    "\n",
    "# Perform thresholding for each array individually\n",
    "for arr, threshold_list in zip(wav_coff_1, thresholds):\n",
    "    thresholded_arr = []\n",
    "    for threshold in threshold_list:\n",
    "        thresholded_arr.append(pywt.threshold(arr, threshold, 'hard'))\n",
    "    wav_coff_thresh.append(thresholded_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "C_fYd_VgAKo1"
   },
   "outputs": [],
   "source": [
    "thresholds_percentage = [0.05, 0.1, 0.15, 0.2]\n",
    "thresholds_1 = []\n",
    "wav_coff_thresh_1 = []\n",
    "thresholds_2 = []\n",
    "wav_coff_thresh_2 = []\n",
    "\n",
    "# Find the threshold for each array in the list\n",
    "for i, (arr_1, arr_2) in enumerate(zip(wav_coff_1, wav_coff_2)):\n",
    "    max_value_1 = np.max(arr_1)\n",
    "    max_value_2 = np.max(arr_2)\n",
    "    thresholds_1.append([])  # Create an empty list for each array\n",
    "    thresholds_2.append([])  # Create an empty list for each array\n",
    "    for j in range(len(thresholds_percentage)):\n",
    "      threshold_1 = max_value_1 * thresholds_percentage[j] \n",
    "      thresholds_1[i].append(threshold_1)\n",
    "      threshold_2 = max_value_2 * thresholds_percentage[j] \n",
    "      thresholds_2[i].append(threshold_2)\n",
    "\n",
    "# Perform thresholding for each array individually\n",
    "for arr_1, threshold_list_1, arr_2, threshold_list_2 in zip(wav_coff_1, thresholds_1, wav_coff_2, thresholds_2):\n",
    "    thresholded_arr_1 = []\n",
    "    thresholded_arr_2 = []\n",
    "    for threshold_1, threshold_2 in zip(threshold_list_1, threshold_list_2):\n",
    "        thresholded_arr_1.append(pywt.threshold(arr_1, threshold_1, 'hard'))\n",
    "        thresholded_arr_2.append(pywt.threshold(arr_2, threshold_2, 'hard'))\n",
    "    wav_coff_thresh_1.append(thresholded_arr_1)\n",
    "    wav_coff_thresh_2.append(thresholded_arr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6sTbqL1Z5yON",
    "outputId": "120678e9-f83e-42bb-daf0-4300cec7ce24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes after thresholding and before quantization:\n",
      "\n",
      "*************** Signal 1 ***************\n",
      "Thresholding of 0.05 ==> 112604224 bytes\n",
      "Thresholding of 0.1 ==> 112604224 bytes\n",
      "Thresholding of 0.15 ==> 112604224 bytes\n",
      "Thresholding of 0.2 ==> 112604224 bytes\n",
      "\n",
      "*************** Signal 2 ***************\n",
      "Thresholding of 0.05 ==> 28151136 bytes\n",
      "Thresholding of 0.1 ==> 28151136 bytes\n",
      "Thresholding of 0.15 ==> 28151136 bytes\n",
      "Thresholding of 0.2 ==> 28151136 bytes\n"
     ]
    }
   ],
   "source": [
    "old_sizes_1 = []\n",
    "old_sizes_2 = []\n",
    "\n",
    "print(\"Sizes after thresholding and before quantization:\\n\")\n",
    "print(\"*************** Signal 1 ***************\")\n",
    "for i,thresh_perecntage in enumerate(thresholds_percentage):\n",
    "  size = sum([lst[i].nbytes for lst in wav_coff_thresh_1])\n",
    "  print(\"Thresholding of\", thresh_perecntage, \"==>\", size, \"bytes\")\n",
    "  old_sizes_1.append(size)\n",
    "\n",
    "print(\"\\n*************** Signal 2 ***************\")\n",
    "for i,thresh_perecntage in enumerate(thresholds_percentage):\n",
    "  size = sum([lst[i].nbytes for lst in wav_coff_thresh_2])\n",
    "  print(\"Thresholding of\", thresh_perecntage, \"==>\", size, \"bytes\")\n",
    "  old_sizes_2.append(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGHrfbVwBiW6"
   },
   "source": [
    "After applying the threshold, quantize the coefficients. A simple way to do that is to store\n",
    "them in a smaller word size. For example, you may decide to typecast the coefficients to\n",
    "int8. Please note that you must first rescale your coefficients such that the maximum and\n",
    "minimum coefficient are within a range that can be represented by int8 type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fp-2d6oXBkSf"
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "###### THIS CODE WAS CREATED FOR ONLY 1 SIGNAL (JUST FOR EXPLANATION) ==> DON'T RUN IT  ######\n",
    "##############################################################################################\n",
    "\n",
    "quantized_coeffs = []\n",
    "\n",
    "# Find the maximum and minimum values for each array in the list\n",
    "for wav_coffy in wav_coff_thresh_1:\n",
    "    quantized_coffy = []\n",
    "    for arr in wav_coffy:\n",
    "        max_value = np.max(arr)\n",
    "        min_value = np.min(arr)\n",
    "        \n",
    "        # Rescale the coefficients to fit within the desired range\n",
    "        new_min = -32768\n",
    "        new_max = 32767\n",
    "        rescaled_coeffs = (arr - min_value) / (max_value - min_value) * (new_max - new_min) + new_min\n",
    "        \n",
    "        # Typecast the rescaled coefficients to int16\n",
    "        quantized_arr = rescaled_coeffs.astype(np.int16)\n",
    "        \n",
    "        # Store the quantized coefficients in the list\n",
    "        quantized_coffy.append(quantized_arr)\n",
    "    quantized_coeffs.append(quantized_coffy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lD-tcUNFEv0D"
   },
   "outputs": [],
   "source": [
    "quantized_coeffs_1 = []\n",
    "quantized_coeffs_2 = []\n",
    "\n",
    "\n",
    "# Find the maximum and minimum values for each array in the list\n",
    "for wav_coffy_1, wav_coffy_2 in zip(wav_coff_thresh_1, wav_coff_thresh_2):\n",
    "    quantized_coffy_1 = []\n",
    "    quantized_coffy_2 = []\n",
    "    for arr_1, arr_2 in zip(wav_coffy_1, wav_coffy_2):\n",
    "        max_value_1 = np.max(arr_1)\n",
    "        min_value_1 = np.min(arr_1)\n",
    "        max_value_2 = np.max(arr_2)\n",
    "        min_value_2 = np.min(arr_2)\n",
    "\n",
    "        # Rescale the coefficients to fit within the desired range\n",
    "        new_min = -32768\n",
    "        new_max = 32767\n",
    "        rescaled_coeffs_1 = (arr_1 - min_value_1) / (max_value_1 - min_value_1) * (new_max - new_min) + new_min\n",
    "        rescaled_coeffs_2 = (arr_2 - min_value_2) / (max_value_2 - min_value_2) * (new_max - new_min) + new_min\n",
    "\n",
    "        # Typecast the rescaled coefficients to int16\n",
    "        quantized_arr_1 = rescaled_coeffs_1.astype(np.int16)\n",
    "        quantized_arr_2 = rescaled_coeffs_2.astype(np.int16)\n",
    "\n",
    "        # Store the quantized coefficients in the list\n",
    "        quantized_coffy_1.append(quantized_arr_1)\n",
    "        quantized_coffy_2.append(quantized_arr_2)\n",
    "\n",
    "    quantized_coeffs_1.append(quantized_coffy_1)\n",
    "    quantized_coeffs_2.append(quantized_coffy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Skn_QF4PBkXf"
   },
   "source": [
    "Find the number of bytes occupied by the coefficients of one image. This should already be\n",
    "smaller than the original size due to the quantization step. However, note that we haven’t\n",
    "compressed the image yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74teXQzujp7t",
    "outputId": "9c8fcc21-fb23-4cd0-e8ad-cf13f411b1df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sizes after thresholding and after quantization:\n",
      "\n",
      "*************** Signal 1 ***************\n",
      "Thresholding of 0.05 ==> 28151056 bytes\n",
      "Thresholding of 0.1 ==> 28151056 bytes\n",
      "Thresholding of 0.15 ==> 28151056 bytes\n",
      "Thresholding of 0.2 ==> 28151056 bytes\n",
      "\n",
      "*************** Signal 2 ***************\n",
      "Thresholding of 0.05 ==> 7037784 bytes\n",
      "Thresholding of 0.1 ==> 7037784 bytes\n",
      "Thresholding of 0.15 ==> 7037784 bytes\n",
      "Thresholding of 0.2 ==> 7037784 bytes\n"
     ]
    }
   ],
   "source": [
    "new_sizes_1 = []\n",
    "new_sizes_2 = []\n",
    "\n",
    "print(\"Sizes after thresholding and after quantization:\\n\")\n",
    "\n",
    "print(\"*************** Signal 1 ***************\")\n",
    "for i,thresh_perecntage in enumerate(thresholds_percentage):\n",
    "  size = sum([lst[i].nbytes for lst in quantized_coeffs_1])\n",
    "  print(\"Thresholding of\", thresh_perecntage, \"==>\", size, \"bytes\")\n",
    "  new_sizes_1.append(size)\n",
    "\n",
    "print(\"\\n*************** Signal 2 ***************\")\n",
    "for i,thresh_perecntage in enumerate(thresholds_percentage):\n",
    "  size = sum([lst[i].nbytes for lst in quantized_coeffs_2])\n",
    "  print(\"Thresholding of\", thresh_perecntage, \"==>\", size, \"bytes\")\n",
    "  new_sizes_2.append(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdZIs9r299ET",
    "outputId": "89fe5f1e-870a-49bb-e652-6c63842c062b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size reduction after quantization:\n",
      "\n",
      "********** Signal 1 **********\n",
      "Thresholding of  0.05  ==> 4.0\n",
      "Thresholding of  0.1  ==> 4.0\n",
      "Thresholding of  0.15  ==> 4.0\n",
      "Thresholding of  0.2  ==> 4.0\n",
      "\n",
      "********** Signal 2 **********\n",
      "Thresholding of  0.05  ==> 4.0\n",
      "Thresholding of  0.1  ==> 4.0\n",
      "Thresholding of  0.15  ==> 4.0\n",
      "Thresholding of  0.2  ==> 4.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Size reduction after quantization:\\n\")\n",
    "\n",
    "print(\"********** Signal 1 **********\")\n",
    "for old, new, thresh in zip(old_sizes_1, new_sizes_1, thresholds_percentage):\n",
    "  print(\"Thresholding of \", thresh, \" ==>\", old/new)\n",
    "\n",
    "print(\"\\n********** Signal 2 **********\")\n",
    "for old, new, thresh in zip(old_sizes_1, new_sizes_1, thresholds_percentage):\n",
    "  print(\"Thresholding of \", thresh, \" ==>\", old/new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vdd4CRI72DiC"
   },
   "source": [
    "**`Done`**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
